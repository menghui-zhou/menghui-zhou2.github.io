

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

	<head>
		<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
		<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
		<link rel="stylesheet" href="jemdoc.css" type="text/css" />
		<title>Menghui Zhou </title>
	</head>

	<body>
		<div id="wrap">
		
		<div id="toptitle">
			<h1>Menghui Zhou </h1>
		</div>

		<table class="imgtable"><tr><td>
			<img src="photos/lingpan.jpg" alt="" width="120px" height="160px" />&nbsp;</td>
			<td align="left"><p>Postdoctoral Fellow<br /> 
			<a href="https://mila.quebec/">MILA (Montreal Institute for Learning Algorithms)</a> <br />

			<p>(Incoming) Assistant Professor<br/> 
			<a href="https://ece.hkust.edu.hk/">Department of Electronic and Computer Engineering</a><br/> 
			<a href="https://hkust.edu.hk/">Hong Kong University of Science and Technology (HKUST)</a> <br/>

			<p>
			Email: penny.ling.pan [@] gmail [DOT] com 
			</p>
		</td></tr></table>
		

		<h2>About Me</h2>
		I will be joining the <a href="https://ece.hkust.edu.hk/">Department of Electronic and Computer Engineering</a> at the <a href="https://hkust.edu.hk/">Hong Kong University of Science and Technology (HKUST)</a> as a Tenure-Track Assistant Professor  in Spring 2024.  </p>

		I am a postdoctoral fellow at <a href="https://mila.quebec/">MILA</a> supervised by <a href="https://yoshuabengio.org/">Prof. Yoshua Bengio</a>. 
		Prior to that, I received my Ph.D. from the <a href="http://iiis.tsinghua.edu.cn/en/">Institute for Interdisciplinary Information Sciences (IIIS)</a> (headed by <a href="https://iiis.tsinghua.edu.cn/yao/">Prof. Andrew Yao</a>), <a href="http://www.tsinghua.edu.cn/publish/thu2018en/index.html">Tsinghua University</a> in 2022, advised by <a href="http://iiis.tsinghua.edu.cn/~huang/">Prof. Longbo Huang</a>. 
		I received my B.E. from the <a href="http://sdcs.sysu.edu.cn/">School of Computer Science and Engineering</a>, <a href="http://www.sysu.edu.cn/2012/en/index.htm">Sun Yat-Sen (Zhongshan) University</a>, Guangzhou, China in 2017. </p>
		
		During my Ph.D., I was fortunate to visit <a href="https://ai.stanford.edu/">Stanford University</a> advised by <a href="https://ai.stanford.edu/~tengyuma/">Prof. Tengyu Ma</a>, <a href="https://www.ox.ac.uk/">University of Oxford</a> advised by <a href="https://www.cs.ox.ac.uk/people/shimon.whiteson/">Prof. Shimon Whiteson</a>, and I was a research intern in the <a href="https://www.microsoft.com/en-us/research/group/machine-learning-research-group/">Machine Learning Group</a> at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/">Microsoft Research Asia</a> advised by <a href="https://weichen-cas.github.io/">Dr. Wei Chen</a>.
		I was also a recepient of <a href="https://www.microsoft.com/en-us/research/academic-program/fellowships-microsoft-research-asia/#!fellows">Microsoft Research Ph.D. Fellowship (Asia)</a> (2020). </p>

		Please drop me an email if you are interested in collaborating with me.

		<div class="infoblock">
		<div class="blockcontent">
		<p> <b>Prospective Students</b>: I am actively looking for self-motivated students (including undergraduate/graduate students and research assistants) who are interested in the areas of artificial intelligence, machine learning, deep reinforcement learning, generative flow networks, and multi-agent systems. I have several PhD/MPhil/RA openings starting in Spring/Fall 2024 at HKUST. Please drop me an email with your CV if you are interested. 
		</p>
		</div></div>
		
		<h2>Research Interests</h2>
		<p>My research interests mainly include theoretical understanding, algorithmic improvements and practical application of <a href="https://milayb.notion.site/The-GFlowNet-Tutorial-95434ef0e2d94c24aab90e69b30be9b3">generative flow networks (GFlowNets)</a>, reinforcement learning and multi-agent systems. 
		I focus on developing robust, efficient, and practical deep reinforcement learning algorithms. I am also interested in the application of reinforcement learning in practical problems like computational sustainability and drug discovery.
		</p>
			
		<h2>Publications </h2>
			(* indicates equal contribution) 
			<ul>
				<li>
					<p>
					<b>Let the Flows Tell: Solving Graph Combinatorial Problems with GFlowNets</b> </br>
					Dinghuai Zhang, Hanjun Dai, Nikolay Malkin, Aaron Courville, Yoshua Bengio, <b>Ling Pan</b><br/>
					Preprint <br/>
					[<a href="https://arxiv.org/pdf/2305.17010.pdf">PDF</a>] [<a href="https://github.com/zdhNarsil/GFlowNet-CombOpt">Code</a>]<br/>
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>Distributional GFlowNets with Quantile Flows</b> </br>
					Dinghuai Zhang*, <b>Ling Pan*</b>, Ricky T.Q. Chen, Aaron Courville, Yoshua Bengio<br/>
					Preprint <br/>
					[<a href="https://arxiv.org/pdf/2302.05793.pdf">PDF</a>] [<a href="https://github.com/zdhNarsil/Distributional-GFlowNets">Code</a>]<br/>
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>Better Training of GFlowNets with Local Credit and Incomplete Trajectories</b> </br>
					<b>Ling Pan</b>, Nikolay Malkin, Dinghuai Zhang, Yoshua Bengio<br/>
					In Fortieth International Conference on Machine Learning (<b>ICML</b>), Hawaii, USA, 2023 <br/>
					[<a href="https://arxiv.org/pdf/2302.01687.pdf">PDF</a>] [<a href="https://github.com/ling-pan/FL-GFN">Code</a>]<br/>
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>Stochastic Generative Flow Networks</b> </br>
					<b>Ling Pan*</b>, Dinghuai Zhang*, Moksh Jain, Longbo Huang, Yoshua Bengio<br/>
					In Thirty-Ninth Conference on Uncertainty in Artificial Intelligence (<b>UAI</b>), Pittsburgh, USA, 2023 <br/>
					<i><font color="Blue">Spotlight (Top 7%)</font></i></br>
					[<a href="https://arxiv.org/pdf/2302.09465.pdf">PDF</a>]<br/>
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>Generative Augmented Flow Networks</b> </br>
					<b>Ling Pan</b>, Dinghuai Zhang, Aaron Courville, Longbo Huang, Yoshua Bengio<br/>
					In Eleventh International Conference on Learning Representations (<b>ICLR</b>), Kigali, Rwanda, 2023 <br/>
					<i><font color="Blue">Spotlight (Top 5%)</font></i></br>
					[<a href="https://openreview.net/pdf?id=urF_CBK5XC0">PDF</a>] [<a href="https://github.com/ling-pan/GAFN">Code</a>]<br/>
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>RLx2: Training a Sparse Deep Reinforcement Learning Model from Scratch</b> </br>
					Yiqin Tan*, Pihe Hu*, <b>Ling Pan</b>, Jiatai Huang, Longbo Huang<br/>
					In Eleventh International Conference on Learning Representations (<b>ICLR</b>), Kigali, Rwanda, 2023 <br/>
					<i><font color="Blue">Spotlight (Top 5%)</font></i></br>
					[<a href="https://arxiv.org/pdf/2205.15043.pdf">PDF</a>] [<a href="https://github.com/tyq1024/RLx2">Code</a>]<br/>
					</p>
				</li>
			</ul>
			<ul>
				<li>
					<p>
					<b>Beyond Conservatism: Diffusion Policies in Offline Multi-agent Reinforcement Learning</b> </br>
					Zhuoran Li, <b>Ling Pan</b>, Longbo Huang<br/>
					Preprint, 2023 <br/>
					[<a href="https://arxiv.org/pdf/2307.01472.pdf">PDF</a>]<br/>
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>E-MAPP: Efficient Multi-Agent Reinforcement Learning with Parallel Program Guidance</b> </br>
					Can Chang, Ni Mu, Jiajun Wu, <b>Ling Pan</b>, Huazhe Xu<br/>
					In Thirty-Sixth Conference on Neural Information Processing Systems (<b>NeurIPS</b>), New Orleans, USA, 2022 <br/>
					<i><font color="Blue">Spotlight (Top 5%)</font></i></br>
					[<a href="https://openreview.net/pdf?id=8LE06pFhqsW">PDF</a>] [<a href="https://sites.google.com/view/e-mapp">Website</a>]<br/>
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>Plan Better Amid Conservatism: Offline Multi-Agent Reinforcement Learning with Actor Rectification</b> </br>
					<b>Ling Pan</b>, Longbo Huang, Tengyu Ma, Huazhe Xu<br/>
					In Thirty-Ninth International Conference on Machine Learning (<b>ICML</b>), Baltimore, USA, 2022 <br/>
					[<a href="https://arxiv.org/pdf/2111.11188.pdf">PDF</a>] [<a href="https://github.com/ling-pan/OMAR">Code</a>] [<a href="https://sites.google.com/view/omar-videos">Website</a>]<br/>
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>Recurrent Softmax Policy Gradient for Delay-Constrained Scheduling</b> </br>
					Pihe Hu, <b>Ling Pan</b>, Yu Chen, Zhixuan Fang, Longbo Huang<br/>
					In Twenty-Third International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing (<b>MobiHoc</b>), Seoul, South Korea, 2022 <br/>
					[<a href="https://arxiv.org/pdf/2208.14074.pdf">PDF</a>]<br/>
					</p>
				</li>
			</ul>
			<ul>
				<li>
					<p>
					<b>Network Topology Optimization via Deep Reinforcement Learning</b> </br>
					Zhuoran Li, Xing Wang, <b>Ling Pan</b>, Lin Zhu, Zhendong Wang, Junlan Feng, Chao Deng, Longbo Huang<br/>
					IEEE Transactions on Communications (<b>TCOM</b>), 2022 <br/>
					[<a href="https://ieeexplore.ieee.org/document/10045737">PDF</a>]<br/>
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>Regularized Softmax Deep Multi-Agent Q-Learning</b> </br>
					<b>Ling Pan</b>, Tabish Rashid, Bei Peng, Longbo Huang, Shimon Whiteson<br/>
					In Thirty-Fifth Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2021 <br/>
					[<a href="https://arxiv.org/pdf/2103.11883.pdf">PDF</a>][<a href="https://github.com/ling-pan/RES">Code</a>]<br/>
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>Exploration in Policy Optimization through Multiple Paths</b></br>
					<b>Ling Pan</b>, Qingpeng Cai, Longbo Huang<br/>
					Journal of Autonomous Agents and Multi-agent Systems (<b>JAAMAS</b>), 2021 <br/>
					[<a href="https://link.springer.com/content/pdf/10.1007/s10458-021-09518-6.pdf">PDF</a>]
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>Softmax Deep Double Deterministic Policy Gradients</b> </br>
					<b>Ling Pan</b>, Qingpeng Cai, Longbo Huang<br/>
					In Thirty-Fourth Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2020<i></i> <br/>
					[<a href="https://arxiv.org/pdf/2010.09177.pdf">PDF</a>][<a href="https://github.com/ling-pan/SD3">Code</a>]
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>Reinforcement Learning with Dynamic Boltzmann Softmax Updates</b> </br>
					<b>Ling Pan</b>, Qingpeng Cai, Qi Meng, Wei Chen, Longbo Huang<br/>
					In Twenty-Ninth International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2020, Yokohama, Japan </br>
					<i>(Acceptance rate: 12.6%)</i> <br/>
					[<a href="https://www.ijcai.org/Proceedings/2020/0276.pdf">PDF</a>]
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>Multi-Path Policy Optimization</b> </br>
					<b>Ling Pan</b>, Qingpeng Cai, Longbo Huang<br/>
					In Nineteenth International Conference on Autonomous Agents and Multi-Agent Systems (<b>AAMAS</b>), 2020, Auckland, New Zealand <br/>
					<i><font color="Blue">Invited for fast-track publication in JAAMAS (Top 5%)</font></i></br>
					[<a href="./papers/mppo/mppo_paper.pdf">PDF</a>]
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>Deterministic Value-Policy Gradients</b></br>
					Qingpeng Cai*, <b>Ling Pan*</b>, Pingzhong Tang<br/>
					In Thirty-Fourth AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2020, New York, USA <br/>
					[<a href="https://arxiv.org/pdf/1909.03939v2.pdf">PDF</a>]
					</p>
				</li>   
			</ul>
			<ul>
				<li>
					<p>
					<b>A Deep Reinforcement Learning Framework for Rebalancing Dockless Bike Sharing Systems</b></br>
					<b>Ling Pan</b>, Qingpeng Cai, Zhixuan Fang, Pingzhong Tang, Longbo Huang<br/>
					In Thirty-Third AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2019, Hawaii, USA <br/>
					<i>(Acceptance rate: 16.2%)</i> <br/>
					[<a href="./papers/bss/bss_paper.pdf">PDF</a>] [<a href="./papers/bss/bss_slides.pdf">Slides</a>] [<a href="./papers/bss/bss_poster.pdf">Poster</a>] <br/>
					</p>
				</li>   
			</ul>			

		<h2>Selected Awards</h2>
			<ul>
				<li>
					<p>Outstanding Doctoral Thesis, by Tsinghua University, 2022<br>
					<i>Thesis: Towards Robust, Efficient, and Practical Deep Reinforcement Learning Algorithms</i></p>
					<i>The only selected computer science doctoral thesis in IIIS, Tsinghua University</i></p>
				</li>
				<li>
					<p>Outstanding Graduate (top 3%), by Tsinghua University, 2022<br>
					<i>Also Beijing outstanding graduate and IIIS, Tsinghua University outstanding graduate, 2022</i></p>
				</li>
				<li>
					<p>China National Scholarship (top 2%), by Ministry of Education of China, 2021</p>
				</li>
				<li>
					<p><a href="https://www.microsoft.com/en-us/research/academic-program/fellowships-microsoft-research-asia/#!fellows">Microsoft Research Asia Fellowship</a>, 2020<br>
					<i><font color="Red">12 outstanding Ph.D. students in computer science in the Asia-Pacific region</font></i></p>
				</li>
				<li>
					<p>China National Scholarship (top 2%), by Ministry of Education of China, 2016</p>
				</li>
				<li>
					<p>China National Scholarship (top 2%), by Ministry of Education of China, 2015</p>
				</li>
				<li>
					<p>China National Scholarship (top 2%), by Ministry of Education of China, 2014</p>
				</li>
			</ul>

		<h2>Professional Activities</h2>
			<ul>
				<li> <p>SPC member:</p> 
					<ul>
						<li>International Joint Conference on Artificial Intelligence (IJCAI), 2021</li>
					</ul>
				</li>
				<li> <p>PC member/Reviewer:</p>
				<ul>
					<li>International Conference on Learning Representations (ICLR), 2022-2023</li>
					<li>Conference on Neural Information Processing Systems (NeurIPS), 2021-2023</li>
					<li>International Conference on Machine Learning (ICML), 2021-2023</li>
					<li>AAAI Conference on Artificial Intelligence (AAAI), 2021</li>
					<li>Transactions of Machine Learning Research (TMLR)</li>
					<li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
				</ul>
				</li>
			</ul>

			
		<h2>Selected Talks/Presentations</h2>
			<ul>
				<li><p>
					<b>Towards Robust, Efficient, and Practical Reinforcement Learning</b> </br>
					Computer Science and Artificial Intelligence Lab (CSAIL), MIT, December, 2021 </br>
					Berkeley Artificial Intelligence Research (BAIR), UC Berkeley, November, 2021 </br>
				</p></li>

				<li><p>
					<b>Regularized Softmax Deep Multi-Agent Q-Learning</b></br>
					<a href="http://rlchina.org/">Reinforcement Learning China Community (RLChina)</a>, May, 2022</br>
					<a href="https://mp.weixin.qq.com/s/EjPEwcvbl0xWAmjeVbPpNg">AI Time NeurIPS Session</a> (by Tsinghua University), February, 2022 </br>
					<a href="http://www.adai.ai/dai/2021/2021.html">Third International Conference on Distributed Artificial Intelligence</a>, January, 2022 </br>
				</p></li>

				<li><p>
					<b>Softmax Deep Double Deterministic Policy Gradients</b></br>
					<a href="http://www.ijcai-saia-yes.org.cn/"> IJCAI-Shanghai Artificial Intelligence Industry Association (SAIA) Young Elite Symposium</a>, July, 2021 </br>
					<a href="http://www.adai.ai/dai/2020/2020.html">Second International Conference on Distributed Artificial Intelligence</a>, October, 2020 </br>
				</p></li>
				
				<li><p>
					<b>A Deep Reinforcement Learning Framework for Rebalancing Dockless Bike Sharing Systems</b></br>
					<a href="http://www.adai.ai/dai/2019/2019.html">First International Conference on Distributed Artificial Intelligence</a>, October, 2019 </br>
					Nanjing University, May, 2019 </br>
				</p></li>
			</ul>

		<div id="footer">
			<div id="footer-text">
				Page generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
			</div>
			</div>
		</div>

	</body>

	<a href='https://clustrmaps.com/site/1ag0t'  title='Visit tracker' style="display: block; text-align: center;"><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=a&t=tt&d=2_DFsGGdQwybgJcT3EtYK9qFtSUxqCloU6qqKkSyJz4'/></a>

</html>
